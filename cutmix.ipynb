{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys  \n",
    "# from pathlib import Path\n",
    "# sys.path[0] = str(Path(sys.path[0]).parent)\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from loguru import logger\n",
    "from collections import defaultdict\n",
    "from src.outlier_detection_methods import FewShotDetector, NaiveAggregator, local_knn\n",
    "from src.utils.utils import (\n",
    "    set_random_seed, load_model, merge_from_dict\n",
    ")\n",
    "from src.augmentations import __dict__ as AUGMENTATIONS\n",
    "from typing import Dict\n",
    "from types import SimpleNamespace\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import Tensor\n",
    "from pathlib import Path\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from src.utils.data_fetchers import get_task_loader, get_test_features\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "dataset = \"mini_imagenet\"\n",
    "n_way = 5\n",
    "n_shot = 1\n",
    "n_query = 1\n",
    "n_tasks = 1000\n",
    "backbone = 'resnet12'\n",
    "training = 'feat'\n",
    "layers='4_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 15:08:03.902 | INFO     | __main__:<module>:3 - Loading data...\n",
      "100%|██████████| 12000/12000 [00:00<00:00, 2873795.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "\n",
    "logger.info(\"Loading data...\")\n",
    "data_loader = get_task_loader(dataset,\n",
    "                              n_way,\n",
    "                              n_shot,\n",
    "                              n_query,\n",
    "                              n_tasks,\n",
    "                              split=\"test\",\n",
    "                              n_workers=6)\n",
    "\n",
    "# average_train_features = {}\n",
    "# std_train_features = {}\n",
    "# for layer in layers.split('-'):\n",
    "#     _, _, average_train_features[layer], std_train_features[layer] = get_test_features(\n",
    "#         backbone, dataset, training, layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 15:08:04.139 | INFO     | __main__:<module>:1 - Building model...\n",
      "2022-02-03 15:08:04.140 | INFO     | src.utils.utils:load_model:110 - Fetching data...\n",
      "100%|██████████| 38400/38400 [00:00<00:00, 2813051.67it/s]\n",
      "2022-02-03 15:08:04.977 | INFO     | src.utils.utils:load_model:113 - Building model...\n",
      "2022-02-03 15:08:07.762 | INFO     | __main__:<module>:9 - Loading mean/std from base set ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights from data/models/resnet12_mini_imagenet_feat.pth\n",
      "Missing keys []\n",
      "Unexpected keys []\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Building model...\")\n",
    "weights = Path('data') / 'models' / f'{backbone}_{dataset}_{training}.pth'\n",
    "feature_extractor = load_model(backbone=backbone,\n",
    "                               weights=weights,\n",
    "                               dataset_name=dataset,\n",
    "                               device='cuda')\n",
    "feature_extractor.eval()\n",
    "\n",
    "logger.info(\"Loading mean/std from base set ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid(images: Tensor):\n",
    "    fig = plt.figure(figsize=(15, 75))\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                     nrows_ncols=(1, 5),  # creates 2x2 grid of axes\n",
    "                     axes_pad=0.3,  # pad between axes in inch.\n",
    "                     )\n",
    "    std = torch.Tensor([0.229, 0.224, 0.225]).to(images.device).view(3, 1, 1)\n",
    "    mean = torch.Tensor([0.485, 0.456, 0.406]).to(images.device).view(3, 1, 1)\n",
    "    shifted = images * std + mean\n",
    "    for ax, im in zip(grid, shifted):\n",
    "        # Iterating over the grid returns the Axes.\n",
    "        ax.imshow(im.permute(1, 2, 0))\n",
    "        \n",
    "def gram(t1: Tensor, t2: Tensor):\n",
    "    \"\"\"\n",
    "    t1: [N1, d]\n",
    "    t2: [N2, d]\n",
    "    returns: [N1, N2]\n",
    "    \"\"\"\n",
    "    assert len(t1.size()) == 2, \"Only accepts pooled images\"\n",
    "#     t1 = F.normalize(t1, dim=1)\n",
    "#     t2 = F.normalize(t2, dim=1)\n",
    "    return torch.cdist(t1, t2) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutmix(support, query):\n",
    "    lam = 0.5\n",
    "\n",
    "    image_h, image_w = support.shape[2:]\n",
    "    cx = np.random.uniform(0, image_w)\n",
    "    cy = np.random.uniform(0, image_h)\n",
    "    w = image_w * np.sqrt(1 - lam)\n",
    "    h = image_h * np.sqrt(1 - lam)\n",
    "    x0 = int(np.round(max(cx - w / 2, 0)))\n",
    "    x1 = int(np.round(min(cx + w / 2, image_w)))\n",
    "    y0 = int(np.round(max(cy - h / 2, 0)))\n",
    "    y1 = int(np.round(min(cy + h / 2, image_h)))\n",
    "\n",
    "    augmented = query.clone()\n",
    "    augmented[:, :, y0:y1, x0:x1] = support[:, :, y0:y1, x0:x1]\n",
    "    return augmented\n",
    "\n",
    "def mixup(support, query):\n",
    "    lam = 0.5\n",
    "    augmented_id = lam * query + (1 - lam) * support\n",
    "    return augmented_id\n",
    "\n",
    "def random_noise(support, query):\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:02, 37.16it/s]\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1 - Check that images and their augmented versions look like each other\n",
    "aug = random_noise\n",
    "sim_ratio_originals = []\n",
    "sim_ratio_mixed = []\n",
    "with torch.no_grad():\n",
    "    for i, (support, support_labels, query, query_labels, _) in tqdm(enumerate(data_loader)):\n",
    "        query_id = query[:5]\n",
    "        query_ood = query[5:]\n",
    "        augmented_id = aug(support, query_id)\n",
    "        augmented_ood = aug(support, query_ood)\n",
    "        \n",
    "#         plot_grid(support)\n",
    "#         plot_grid(augmented_id)\n",
    "#         plot_grid(augmented_ood)\n",
    "        \n",
    "        feat_s = feature_extractor(support.cuda(), layers)[layers].mean((-2, -1)).cpu()\n",
    "        feat_q_id = feature_extractor(query_id.cuda(), layers)[layers].mean((-2, -1)).cpu()\n",
    "        feat_q_ood = feature_extractor(query_ood.cuda(), layers)[layers].mean((-2, -1)).cpu()\n",
    "        aug_feat_q_id = feature_extractor(augmented_id.cuda(), layers)[layers].mean((-2, -1)).cpu()\n",
    "        aug_feat_q_ood = feature_extractor(augmented_ood.cuda(), layers)[layers].mean((-2, -1)).cpu()\n",
    "        \n",
    "        ratio_original = gram(feat_s, feat_q_ood).diagonal() / gram(feat_s, feat_q_id).diagonal()\n",
    "        ratio_mixed = gram(feat_s, aug_feat_q_ood).diagonal() / gram(feat_s, aug_feat_q_id).diagonal()\n",
    "        sim_ratio_originals.append(ratio_original)\n",
    "        sim_ratio_mixed.append(ratio_mixed)\n",
    "        \n",
    "#         logger.info(f\"Separation in embedded space: {sim_ratio_original}\")\n",
    "#         logger.info(f\"Separation in mixed space: {sim_ratio_mixed}\")\n",
    "        #logger.info(f\"Distances between image and mixed: {sim_aug.diagonal()}\")\n",
    "        if i >= 100:\n",
    "            break\n",
    "#     plt.hist(sim_ratio_originals, bins=20, facecolor='brown', alpha=0.5, label='Original')\n",
    "#     plt.hist(sim_ratio_mixed, bins=20, facecolor='orange', alpha=0.5, label='Mixed')\n",
    "    separation_improvement = torch.cat(sim_ratio_mixed) - torch.cat(sim_ratio_originals)\n",
    "    plt.hist(separation_improvement, facecolor='orange', alpha=0.5)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
